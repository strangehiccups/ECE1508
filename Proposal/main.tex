\documentclass[11pt,a4paper,BCOR12mm, headexclude, footexclude, openright]{scrartcl} 
\usepackage{newpxtext}
\usepackage[british]{babel}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage[T1]{fontenc}
\usepackage{href-ul}
%\usepackage[scaled=0.85]{beramono}            % load a nice TT font
%\lstset{basicstyle=\ttfamily, language=sh}  
\lstset{columns=fullflexible,basicstyle=\ttfamily}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{ifthen}
\usepackage{amsmath,amsfonts,amsthm}
%\usepackage{sfmath}
%\usepackage{eulervm}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{sectsty}
\usepackage{bbm}
\usepackage{commands}
\usepackage{tikz,pgfplots}
\usepackage{tikz-cd}
\usetikzlibrary{patterns,intersections,matrix,fit,trees,positioning,chains,shapes.geometric,shapes,angles,quotes,pgfplots.fillbetween}
\usetikzlibrary{arrows,math}
\usepackage{tikz-cd}
\usepackage{tikz-3dplot}
\usetikzlibrary{arrows.meta,bending}
\usepackage{tikzsymbols}
\usepackage{tikzpeople}
\usetikzlibrary{calc}
\usetikzlibrary{chains,positioning,shapes.symbols,fadings,shadows,backgrounds}
\usetikzlibrary{decorations.pathmorphing, decorations.pathreplacing}
\usetikzlibrary{shapes.callouts}
\usetikzlibrary{shapes.arrows,shadings}
\usetikzlibrary{decorations.text}
\usepackage{algorithm,algorithmic}
%\KOMAoptions{optionenliste}
%\KOMAoptions{Option}{Werteliste}
\usepackage{listings}
\usepackage{inconsolata}
\lstset{%
	numbers=left,
	numberstyle=\tiny,
	basicstyle=\ttfamily\fontfamily{courier}\footnotesize,
}


\renewcommand{\arraystretch}{1.1}
\newcommand{\horrule}[1]{\rule{\linewidth}{#1}}
\setlength{\textheight}{250mm}
\setlength{\textwidth}{175mm}
\setlength{\hoffset}{-25mm}
\setlength{\voffset}{-15mm}
\allsectionsfont{\centering \normalfont\scshape}


\numberwithin{equation}{section} 
\numberwithin{figure}{section}
\numberwithin{table}{section} 


\newcommand{\ProjectTopic}{Automatic Speech Recognition (ASR)}
\newcommand{\ProjectCat}{Open-ended}
\setlength\parindent{0pt}

\fancypagestyle{plain}
{%
	\renewcommand{\headrulewidth}{0pt}%
	\renewcommand{\footrulewidth}{0.5pt}
	\fancyhf{}%
	\fancyfoot[R]{\emph{\footnotesize Page \thepage\ of \pageref{LastPage}}}%
	\fancyfoot[L]{\emph{\footnotesize \ProjectTopic}}%
}
\pagestyle{plain}

\newcommand{\question}[3]{
	\hrule
	\hrule
	\vspace{3pt}
	Question #1: #2 \hfill #3 Points
	\vspace{3pt}
	\hrule
	\hrule
	\vspace{7pt}
}

\newcommand{\code}[1]{\colorbox{gray!20}{\texttt{#1}}}
\newcommand{\textbox}[2]{
	\begin{center}
		\fbox{
			\begin{minipage}{ {#1} em}
				{#2}
			\end{minipage}
		}
	\end{center} 
}
\begin{document}
	
	\titlehead
	{
		\horrule{.5pt}\\
		University of Toronto\\%
		Department of Electrical and Computer Engineering\\%
		ECE1508: \textbf{Applied Deep Learning}
		\hfill
		A. Bereyhi - Winter 2026
		\vspace{-1ex}\\
		\horrule{.5pt}\\
	}
	\subject{}
	\title{ }
	\subtitle{\normalfont \textit{Course Project}\vspace*{-2.5cm}}
	\date{}
	\maketitle
	
	\textbox{43}{\textbf{Code of Honor.} 
		All external resources used in the project, including research papers, open-source repositories, datasets, and any content or code generated using AI tools, e.g., ChatGPT, GitHub Copilot, Claude, Gemini, must be \textit{clearly cited} in the final submission. The final report must also include \textit{a clear breakdown of individual group member contributions.} Any lack of transparency in the use of external resources or in reporting group contributions will be considered academic dishonesty and will significantly impact the final evaluation.
	}
	
\begin{table}[H]
	\begin{tabular}{l l}
		\hline
		\textbf{Topic} & Automatic Speech Recognition (ASR) \\
		\hline
	\end{tabular}
\end{table}

\paragraph*{Objective} 
Design and implement an Automatic Speech Recognition (ASR) system that converts spoken audio into text, with a primary focus on batch transcription of pre-recorded audio files. We then aim to evaluate the impact of various components of ASR systems on transcription accuracy and generalisability.

\paragraph*{Motivation}
Automatic Speech Recognition is a foundational problem in deep learning with wide-ranging real-world impact. In education, for example, accurate lecture transcription can reduce cognitive load, improve review efficiency, and enable new modes of interaction with learning material \cite{grandview_speech_to_text_api_market_2030}. \linebreak

Beyond its practical value, ASR offers a rich learning opportunity due to the many complex components involved in its implementation, ranging from audio signal processing and feature engineering to layered modeling approaches that combine multiple interdependent models to effectively learn the diversity and temporal structure of speech \cite{nayeem2025automaticspeechrecognitionmodern}.

\paragraph*{Requirements}
\begin{enumerate}
	\item Implementation
    \begin{itemize}
        \item Implement pipeline to compress raw audio data to spectrograms.
        \item Implement a baseline deep neural network model from scratch leveraging the DeepSpeech ASR architecture \cite{hannun2014deepspeechscalingendtoend}.
    \end{itemize}
	\item Evaluation
    \begin{itemize}
        \item Analyse the impact of hyperparameters and modifications/extensions on model performance, and justify the final choice of parameters and model.
        \item Evaluate the performance of the model on different datasets, and against publicly available ASR models.
    \end{itemize}
    \item Potential improvements
    \begin{itemize}
        \item Identify the limitation(s) of the chosen architecture.
        \item Investigate baseline enhancement using a pre-trained language model.
    \end{itemize}
\end{enumerate}

\paragraph*{Milestones}
\begin{enumerate}
    \item Literature review
    \begin{itemize}
        \item ASR architectures used in industry.
        \item Audio datasets suitable for training on limited compute.
        \item Metrics for evaluating ASR model performance.
    \end{itemize}
	\item Implementation \& Testing
        \begin{itemize}
            \item Data preprocessing pipeline.
            \item Training and testing pipeline.
            \item Baseline ASR model.
            \item Iterative improvement to baseline model.
            \item Generalisation to other datasets.
        \end{itemize}
    \item Evaluation \& Analysis
        \begin{itemize}
            \item Effects of modifications/extensions to baseline model.
            \item Compare with publicly available models.
            \item Perform ablation experiments (stretch goal).
        \end{itemize}
    \item Final Presentation and Report
\end{enumerate}

\paragraph*{Submission Guidelines} The main body of work is submitted through Git. In addition, each group submits a final paper and gives a presentation. In this respect, please follow these steps.
\begin{itemize}
	\item Each group must maintain a Git repository, e.g., GitHub or GitLab, for the project. By the time of final submission, the repository should have
	\begin{itemize}
		\item Well-documented codebase
		\item Clear \texttt{README.md} with setup and usage instructions
		\item A \texttt{requirements.txt} file listing all required packages or an \texttt{environment.yaml} file with a reproducible environment setup
		\item Demo script or notebook showing sample input-output
		\item \textit{If applicable,} a \texttt{/doc} folder with extended documentation
	\end{itemize}
	\item A final report (maximum \textit{5 pages}) must be submitted in a PDF format. The report should be written in the provided formal style, including an abstract, introduction, method, experiments, results, and conclusion.\\
	\textbf{Important:} Submissions that do not use template are considered \textit{incomplete.}
	\item A 5-minute presentation (maximum \textit{5 slides including the title slide}) is given on the internal seminar on Week 15, i.e., \textit{Dec 8 to Dec 12,} by the group. For presentation, any template can be used.
\end{itemize}

\paragraph*{Final Notes} While planning for the milestones please consider the following points.
\begin{enumerate}
    \item You are encouraged to explore innovative approaches to conditioning or generation as long as the core objectives are met.
    \item While computational resources are limited, carefully chosen datasets and training setups can make even diffusion models feasible. Trade-offs, e.g., resolution, training steps, are expected and should be justified.
    \item Teams are expected to manage their computing needs and are advised to perform early tests to estimate runtime and training feasibility. As graduate students, team members can use facilities provided by the university, e.g., ECE Facility. Teams are expected to inform themselves about the limitations of the available computing resources and design the model accordingly.
\end{enumerate}

\bibliographystyle{unsrt}
\bibliography{ref.bib}

\end{document}